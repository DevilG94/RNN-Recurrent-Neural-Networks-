{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jzHlvfveOoP"
   },
   "source": [
    "# What is RNN?\n",
    "\n",
    "A recurrent neural network (RNN) is a deep learning model that is trained to process and convert a sequential data input into a specific sequential data output.\n",
    "\n",
    "## What is Seqential Data?\n",
    "\n",
    " Sequential data is data—such as words, sentences, audio (Speech) or time-series data—where sequential components are interrelate based on complex semantics and syntax rules.\n",
    "\n",
    "## What are the types of recurrent neural networks?\n",
    "\n",
    "The following are several common RNN types.\n",
    "\n",
    "* **One-to-Many RNNs**: In this architecture, the RNN receives a single input at the beginning (the \"one\" part), and then it generates a sequence of outputs (the \"many\" part).\n",
    "\n",
    "   - This can be useful for tasks such as image captioning, where the input is an image, and the output is a sequence of words describing the content of the image.\n",
    "   - **Example**: *In image captioning, the RNN receives an image as input and generates a sequence of words to describe the contents of the image.*\n",
    "\n",
    "* **Many-to-One RNNs**: Conversely, in many-to-one RNNs, the network receives a sequence of inputs (the \"many\" part) and produces a single output (the \"one\" part).\n",
    "   - This setup is commonly used for tasks like sentiment analysis, where the input is a sequence of words, and the output is a sentiment label (positive or negative).\n",
    "   - **Example**: *In sentiment analysis, the RNN receives a sequence of words representing a movie review and predicts whether the sentiment is positive, negative, and neutral from input reviews*\n",
    "* **Many-to-Many RNNs (Sequence-to-Sequence)**: In this architecture, the RNN takes a sequence of inputs and produces a sequence of outputs, can be of variable lengths.\n",
    "\n",
    "   - This setup is used for tasks such as machine translation, where the input is a sequence of words in one language, and the output is a sequence of words in another language.\n",
    "   - **Example**: *In machine translation, the RNN receives a sequence of words in English and generates a sequence of words in French.*\n",
    "\n",
    "* **Many-to-Many (Synced) RNNs**: In this variant of many-to-many RNNs, the input and output sequences have the same length.\n",
    "\n",
    "   - This architecture is used for tasks like named entity recognition (NER), where the input is a sequence of words, and the output is a sequence of labels indicating named entities.\n",
    "   - **Example**: *In named entity recognition, the RNN receives a sequence of words and generates a sequence of labels indicating whether each word is part of a named entity (e.g., person, organization, location).*\n",
    "\n",
    "\n",
    "### What about One-to-One?\n",
    "\n",
    "While the \"one-to-one\" architecture is straightforward (each input is processed independently, and there are no recurrent connections or feedback loops.) and suitable for certain types of tasks, it doesn't leverage the sequential nature of data or capture temporal dependencies, which are essential for tasks like sequence prediction, time series forecasting, or natural language processing.\n",
    "\n",
    "   - This architecture is used for tasks like simple classification tasks, regression tasks, or tasks where each input represents a standalone instance.\n",
    "\n",
    "   - **Example**: *Suppose you have a dataset of images, and each image is associated with a single label indicating the object in the image. You can train a \"one-to-one\" neural network to classify each image into its respective category without considering any sequential or temporal information.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swzYDvR4iJfV"
   },
   "source": [
    "## How RNN Model Works?\n",
    "\n",
    "Unlike feedforward neural networks, which process each input independently,\n",
    "\n",
    "RNNs maintain an **internal state (memory)** that allows them to *capture temporal dependencies and patterns in sequential data*.\n",
    "\n",
    "\n",
    "\n",
    "* **Sequential Input**: RNNs take sequential input data, such as text, time series, or audio, where the order of the elements matters. Each element in the sequence is typically represented as a vector or a sequence of feature vectors.\n",
    "\n",
    "* **Recurrent Connections**: RNNs have recurrent connections that allow information to persist over time steps. At each time step, the RNN processes an input vector and updates its internal state based on both the current input and the previous state.\n",
    "\n",
    "* **Hidden State Update**: At each time step 𝑡, the RNN computes a new hidden state\n",
    "ℎ\n",
    "𝑡 using the current input\n",
    "𝑥\n",
    "𝑡\n",
    " and the previous hidden state\n",
    "ℎ\n",
    "𝑡\n",
    "−\n",
    "1\n",
    ". This hidden state serves as a summary of the information processed so far and is passed to the next time step.\n",
    "\n",
    "\n",
    "## **ℎ 𝑡 = 𝑓(𝑊 ℎ ⋅ ℎ 𝑡−1 + 𝑊 𝑥 ⋅𝑥 𝑡 + 𝑏)**\n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "* ℎ\n",
    "𝑡 is the hidden state at time step 𝑡\n",
    "\n",
    "* 𝑓 is the activation function (e.g., tanh or ReLU)\n",
    "\n",
    "* 𝑊\n",
    "ℎ\n",
    "is the weight matrix for the recurrent connections\n",
    "\n",
    "* 𝑊\n",
    "𝑥\n",
    " is the weight matrix for the input connections\n",
    "\n",
    "* 𝑏 is the bias vector\n",
    "\n",
    "* **Output**: Depending on the task, the RNN may produce an output at each time step (sequence-to-sequence) or only at the final time step (sequence-to-vector). The output at each time step 𝑡 is computed based on the current hidden state\n",
    "ℎ\n",
    "𝑡.\n",
    "\n",
    "* **Training**: RNNs are typically trained using backpropagation through time (BPTT), which is an extension of the standard backpropagation algorithm. BPTT computes the gradients of the loss function with respect to the model parameters (weights and biases) by unrolling the network through time and applying the chain rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQwyotFjdnEM"
   },
   "source": [
    "# How to convert words into vectors?\n",
    "\n",
    "In Recurrent Neural Networks (RNNs), integer encoding and word embedding are two common techniques used to represent words as vectors before feeding them into the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RZavg1IVWywU"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u0gtOaf8XJNZ",
    "outputId": "6fa8b2fb-574b-4707-fafb-1ff0549b177d"
   },
   "outputs": [],
   "source": [
    "(train_input,train_target),(test_input,test_target) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GlZ-fmWzXZGp",
    "outputId": "01b39066-4beb-4de2-ddbd-76a98c4ed4f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 22665,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 21631,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 31050,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zkrE7hwPXdmD",
    "outputId": "2873cd9c-fa7a-4020-f0f1-b0b80cad9d0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DbwhaTimXt-R"
   },
   "outputs": [],
   "source": [
    "#from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kFw0Gv_AXhnx"
   },
   "outputs": [],
   "source": [
    "train_input = pad_sequences(train_input,padding='post',maxlen=100)\n",
    "test_input = pad_sequences(test_input,padding='post',maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obAYbu1gck_Y"
   },
   "source": [
    "## Integer Encoding:\n",
    "\n",
    "Integer encoding involves assigning a unique integer index to each word in the vocabulary.\n",
    "\n",
    "Each word in the input text is replaced by its corresponding integer index.\n",
    "\n",
    "Integer encoding is a simple and efficient way to represent words as numerical values. However, it does not capture the semantic relationships between words.\n",
    "\n",
    "Integer-encoded sequences are typically one-hot encoded before being fed into the RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMzs8BwXX4Ns",
    "outputId": "a2900295-cadb-4884-e3c0-06b39dae526e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,121</span> (4.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,121\u001b[0m (4.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,121</span> (4.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,121\u001b[0m (4.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(SimpleRNN(32, input_shape=(100,1), return_sequences=False))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UQ0KdXDnYHrB",
    "outputId": "82e2d85f-287e-4dc9-8091-421a51b4d1b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.5106 - loss: 0.6928 - val_accuracy: 0.5105 - val_loss: 0.6931\n",
      "Epoch 2/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.5045 - loss: 0.6931 - val_accuracy: 0.5126 - val_loss: 0.6924\n",
      "Epoch 3/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.5105 - loss: 0.6925 - val_accuracy: 0.5120 - val_loss: 0.6926\n",
      "Epoch 4/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.5148 - loss: 0.6919 - val_accuracy: 0.5106 - val_loss: 0.6935\n",
      "Epoch 5/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.5081 - loss: 0.6925 - val_accuracy: 0.5130 - val_loss: 0.6923\n",
      "Epoch 6/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.5108 - loss: 0.6935 - val_accuracy: 0.5104 - val_loss: 0.6922\n",
      "Epoch 7/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.5145 - loss: 0.6921 - val_accuracy: 0.5102 - val_loss: 0.6925\n",
      "Epoch 8/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.5080 - loss: 0.6930 - val_accuracy: 0.5060 - val_loss: 0.6946\n",
      "Epoch 9/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.4992 - loss: 0.6933 - val_accuracy: 0.5066 - val_loss: 0.6929\n",
      "Epoch 10/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.5102 - loss: 0.6924 - val_accuracy: 0.5090 - val_loss: 0.6929\n",
      "Epoch 11/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.5135 - loss: 0.6923 - val_accuracy: 0.5104 - val_loss: 0.6930\n",
      "Epoch 12/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.5173 - loss: 0.6921 - val_accuracy: 0.5143 - val_loss: 0.6920\n",
      "Epoch 13/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.5168 - loss: 0.6916 - val_accuracy: 0.5112 - val_loss: 0.6935\n",
      "Epoch 14/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.5161 - loss: 0.6919 - val_accuracy: 0.5111 - val_loss: 0.6921\n",
      "Epoch 15/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.5159 - loss: 0.6916 - val_accuracy: 0.5050 - val_loss: 0.6941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x212c5db62d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_input,train_target,epochs=15,validation_data=(test_input,test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mn3kVZzVb-Nc"
   },
   "source": [
    "\n",
    "## Word Embedding:\n",
    "\n",
    "Word embedding is a dense vector representation of words in a high-dimensional space, during the training process to capture semantic relationships between words. It is capable of capturing context and meaning from the surrounding words in a sequence.\n",
    "\n",
    "**Note:** Words with similar meanings are represented by similar vectors in the embedding space.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "V_gPfLOAZejV"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U90uxh2Xbsn9"
   },
   "source": [
    "`embeddings_initializer='uniform'` is an argument passed to the Embedding layer in the Keras model. It specifies the method used to initialize the embedding weights, which are the vectors that represent each word in the vocabulary.\n",
    "\n",
    "The 'uniform' initializer randomly initializes the weights within a uniform distribution. This means that each weight is sampled from a uniform distribution between a lower and upper bound. The default lower and upper bounds are -1 and 1, respectively.\n",
    "\n",
    "-- It is often used when there is no prior knowledge about the relationships between the words in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNdzHYJFZefq",
    "outputId": "618f4fe0-094c-4d23-8391-0d778b1e63af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_2 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(Embedding(10000, 2, input_length=100, embeddings_initializer='uniform'))\n",
    "model_1.add(SimpleRNN(32,return_sequences=False))\n",
    "model_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVUKV_q2Zec3",
    "outputId": "b92fe152-c414-4510-aafa-fc6ef0be11c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_1_1/embedding_1/GatherV2 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_1544\\3951459324.py\", line 2, in <module>\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 51, in train_step\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 901, in __call__\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 212, in call\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 175, in call\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 560, in call\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 901, in __call__\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 140, in call\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 4918, in take\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 1967, in take\n\nindices[0,43] = 19308 is not in [0, 10000)\n\t [[{{node sequential_1_1/embedding_1/GatherV2}}]] [Op:__inference_one_step_on_iterator_29118]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model_1\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m model_1\u001b[38;5;241m.\u001b[39mfit(train_input,train_target,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,validation_data\u001b[38;5;241m=\u001b[39m(test_input,test_target))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_1_1/embedding_1/GatherV2 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_1544\\3951459324.py\", line 2, in <module>\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 320, in fit\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 51, in train_step\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 901, in __call__\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 212, in call\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 175, in call\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 560, in call\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 901, in __call__\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 140, in call\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 4918, in take\n\n  File \"C:\\Users\\HP\\anaconda3\\envs\\abhijitg_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 1967, in take\n\nindices[0,43] = 19308 is not in [0, 10000)\n\t [[{{node sequential_1_1/embedding_1/GatherV2}}]] [Op:__inference_one_step_on_iterator_29118]"
     ]
    }
   ],
   "source": [
    "model_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model_1.fit(train_input,train_target,epochs=5,validation_data=(test_input,test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5K21IZshu2B"
   },
   "source": [
    "Little overfitting but better accuracy than Interger Encoding Vectors.\n",
    "\n",
    "Word embeddings are more expressive than integer encoding and are widely used in natural language processing, NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oJXZKPwg01Z"
   },
   "source": [
    "## Applications of RNN\n",
    "\n",
    "RNNs are well-suited for tasks involving sequential data, such as natural language processing (e.g., language modeling, machine translation, sentiment analysis), time series analysis (e.g., stock price prediction, weather forecasting), and speech recognition.\n",
    "\n",
    "## What are the limitations of recurrent neural networks?\n",
    "\n",
    "* **Exploding gradient**\n",
    "\n",
    "Gradient exploding refers to the phenomenon where gradients become extremely large during the backpropagation process, causing the weights of the network to update by large amounts.\n",
    "\n",
    "In RNNs, gradient exploding often occurs when the gradients are backpropagated through many time steps, causing them to accumulate and grow exponentially.\n",
    "\n",
    "This can lead to unstable training behavior and make it difficult for the model to converge to a good solution.\n",
    "\n",
    "* **Vanishing gradient**\n",
    "\n",
    "The vanishing gradient problem is a condition where the model’s gradient approaches zero in training. When the gradient vanishes, the RNN fails to learn effectively from the training data, resulting in underfitting.\n",
    "\n",
    "An underfit model can’t perform well in real-life applications because its weights weren’t adjusted appropriately. RNNs are at risk of vanishing and exploding gradient issues when they process long data sequences.\n",
    "\n",
    "* **Slow training time**\n",
    "\n",
    "In RNNs, slow training can be caused by various factors, including gradient exploding or vanishing gradients, which can make it difficult for the model to learn effectively from the training data.\n",
    "\n",
    "Additionally, the computational complexity of training RNNs, especially when processing long sequences or large datasets, can contribute to slow training times.\n",
    "\n",
    " For example, an RNN model can analyze a user’s sentiment from a couple of sentences. However, it requires massive computing power, memory space, and time to summarize a page of an essay.\n",
    "\n",
    "\n",
    "## What are some variants of recurrent neural network architecture?\n",
    "\n",
    "1. **Bidirectional Recurrent Neural Networks (BRNN)**\n",
    "\n",
    "This architecture processes data sequences with forward and backward layers of hidden nodes.\n",
    "\n",
    "The forward layer works similarly to the RNN, which stores the previous input in the hidden state and uses it to predict the subsequent output.\n",
    "\n",
    " Meanwhile, the backward layer works in the opposite direction by taking both the current input and the future hidden state to update the present hidden state.\n",
    "\n",
    "  Combining both layers enables the BRNN to improve prediction accuracy by considering past and future contexts.\n",
    "\n",
    "**Advantage**: Improves prediction accuracy by considering past and future contexts.\n",
    "\n",
    "**Example**: Predicting the word \"enjoy\" in the sentence \"You enjoy data science.\"\n",
    "\n",
    "2. **Long Short-Term Memory (LSTM) Networks**\n",
    "\n",
    "This RNN variant enables the model to expand its memory capacity to accommodate a longer timeline.\n",
    "\n",
    "Whereas, RNN can only remember the immediate past input. It can’t use inputs from several previous sequences to improve its prediction.\n",
    "\n",
    "**Advantage**: Enables the model to remember dependencies over longer sequences.\n",
    "\n",
    "**Example**: \"You love data science. Your favorite topic is RNN.\", the LSTM might recognize the relationship between \"data science\" and \"RNN\" as related topics.\n",
    "\n",
    "3. **Gated Recurrent Units (GRU)**\n",
    "\n",
    "It is an RNN that enables selective memory retention. The model adds an update and forgets the gate to its hidden layer, which can store or remove information in the memory.\n",
    "\n",
    "**Advantage**: Provides a balance between memory retention and computational efficiency. Selectively remembering important information while discarding irrelevant details.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## How do transformers overcome the limitations of recurrent neural networks?\n",
    "\n",
    "Transformers are deep learning models that use self-attention mechanisms in an encoder-decoder feed-forward neural network. They can process sequential data the same way that RNNs do.\n",
    "\n",
    "* **Self-attention**\n",
    "\n",
    "Transformers don’t use hidden states to capture the interdependencies of data sequences. Instead, they use a self-attention head to process data sequences in parallel.\n",
    "\n",
    "This enables transformers to train and process longer sequences in less time than an RNN does. With the self-attention mechanism, transformers overcome the memory limitations and sequence interdependencies that RNNs face.\n",
    "\n",
    "Transformers can process data sequences in parallel and use positional encoding to remember how each input relates to others.\n",
    "\n",
    "* **Parallelism**\n",
    "\n",
    "Transformers solve the gradient issues that RNNs face by enabling parallelism during training. By processing all input sequences simultaneously, a transformer isn’t subjected to backpropagation restrictions because gradients can flow freely to all weights.\n",
    "\n",
    "They are also optimized for parallel computing, which graphic processing units (GPUs) offer for generative AI developments. Parallelism enables transformers to scale massively and handle complex NLP tasks by building larger models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zg-XaXphtja1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
